\section{Discussion}
\label{sec:discussion}

Overall, the results show that our procedure worked and we managed to model reconstructions of the partial femur bones. 
At the time of writing, we are ranked 37 out of 54 on the SMIR challenge~\cite{smir}. 
Besides interpreting these working fundamentals, this section discusses where and how they could be improved.
		
%% --------------------------------------------

\subsection{Kernel Function}
\label{subsec:kernfuncdisc}

We chose our kernel function based on the idea that we need to model both very smooth, long parts and very convoluted, shorter parts in order to model all parts of the bone. 
Therefore, we thought that a combination of kernels with varying degrees of smoothness would yield a good result for modelling all of the different parts and properties of the femur bone. 

Furthermore, we also considered using kernels with a higher scaling factor along the $z$-axis, which in this case would be the length of the bone. 
However, in practice, we could not make out a meaningful difference for the results with such a scaled kernel and thus decided to stick to the uniform kernels.

Nonetheless, the kernel function is a part of the reconstruction process where there is a high degree of variability with many different kernel functions possible. 
Unfortunately, testing the performance of the kernel functions in practice is a rather time consuming and difficult process.
Not only do all the computations have to be redone for every new kernel, but the performance evaluation is also not very clear cut as we can not test the distances of our reconstruction to the ground truth for every new kernel.
This means that the evaluation of each kernel has to be estimated by hand based on the intermediary results, and, particularly on the fit of the registrations. 
As our full pipeline was only finished in a late stage of the project, we were not able to test as intensely as would be necessary in order to find a more sophisticated kernel.

%% --------------------------------------------

\subsection{Kernel Model}
\label{subsec:kernmodeldisc}

In \autoref{fig:kernel_model} we can see the mean and some random samples of the kernel model resulting from our kernel function. 
While the mean looks very realistic, as soon as we sample there are a lot of wobbly sections appearing, especially along the middle part of the bone. 
This is not necessarily bad, as in this step we want a flexible model to fit the training data as good as possible.
Thus, in general we would assume the samples from our kernel model can have such deformations.
However, for our kernel this is quite extreme in some cases, \eg the rightmost sample.
This could likely be fixed using a different kernel function with a smaller scale.

%% --------------------------------------------

\subsection{Registrations}
\label{subsec:registrresultsdisc}
The results shown in \autoref{tbl:registration_distance} can give a good indication of how well the trained model will perform.
As we can not evaluate the distances of the final reconstructions arbitrarily often for different kernels, this is one of the most important metrics for us to improve when searching for better kernels.

The mean average distance of $0.63$ is rather high as we had intermediary results for some kernels with average distances as low as $0.3$. 
This could probably be pushed even further by using lower $\sigma$ values, a lower tolerance for approximating the GP and more point samples from the shape. 
But of course this leads to very high computation times for even a single registration.
As we did not have the necessary time, we could not try out these ideas any further.

We can also see that the Hausdorff distance is higher than the average distance by quite a big margin. This indicates that there are some outlying points that could only be modelled poorly.

As it stands, the fit of our model to the training data is certainly reasonable.
However, this would likely be one of the major points where the model could be improved.

%% --------------------------------------------

\subsection{Trained Model}
\label{subsec:trainedmodeldisc}

Looking at \autoref{fig:trained_model}, some samples of our trained model seem to deviate quite a bit from the normal bone shapes we would expect to sample here. 
In particular, the intricate curvatures along the head, neck, trochanter and condyles pose problems for our model.

This could likely be fixed by using more accurate kernels or possibly even implementing a Changepoint kernel.

%% --------------------------------------------

\subsection{Reconstruction of Partial Bones}
\label{subsec:reconresultsdisc}

In \autoref{fig:reconstructed} showing the fully reconstructed bones, we recognize a reoccurrence of the problems we have had with our trained model: it has some difficulties reconstructing the details at both ends of the femur while still sometimes being too wiggly in the body region. 
This is of course a direct consequence from the problems of the trained model.

When we are comparing the distances of the reconstructions from \autoref{tbl:reconstructed_distance} with their visualizations from \autoref{fig:reconstructed}, we have to keep in mind that these scores are only generated for the missing parts of the bone. 
For example, the misshaped head of the third bone is not explicitly considered in the distance measurements as only the right side of the bone needed to be reconstructed. 
Still, we can clearly see the misalignments of the predictions indicated by the distances in the reconstructed images.

Nevertheless, for some examples the model works quite well.
Bones 1 and 9, for example, look quite realistic and have low average and Hausdorff distances. 
In both cases the head of the bone had to be reconstructed. 
Yet, bone 5, where the entire upper half had to be reconstructed, performed extremely poorly. 
As can be seen here, having to reconstruct a larger part of the bone justifiably leads to less accurate results.

Interestingly, while the average distances of the reconstructions increase considerably in comparison to fitting the training data, the Hausdorff distance only increases by half when comparing the training data and the reconstruction. 
This shows that the biggest outliers for the predicted shapes are not much farther away from the correct fit than they were for the fitting of the training data.

In order to improve the reconstructions, the model would first and foremost have to be improved. 
Other than that, the only possible improvement that comes to mind would be to sample a higher number of points or even use all points for the ICP.
However, this would again go hand in hand with an increase in computation time.
